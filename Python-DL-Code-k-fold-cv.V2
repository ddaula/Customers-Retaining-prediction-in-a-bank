#Basic Neural Network for predicting whether a customer will stay with the bank or leave the bank based on the feature set provided.

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#Read the file
dataset=pd.read_csv('C:/Users/Darmesh_D/Documents/deep learning/Artificial_Neural_Networks/Artificial_Neural_Networks/Churn_Modelling.csv')

X=dataset.copy()
Y=dataset.copy()
#Drop the features which donot contribute to the training/predictions.
#X contains independent variables/features
X.drop(['RowNumber', 'CustomerId', 'Surname','Exited'],axis=1,inplace=True)
#Y contains the actual(Output) values.
Y.drop(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',
       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',
       'IsActiveMember', 'EstimatedSalary'],axis=1,inplace=True)

#create factor variable for string type features
geography=pd.get_dummies(X['Geography'],drop_first=True)
gender=pd.get_dummies(X['Gender'],drop_first=True)

#drop the columns after the factore variables are created.
X.drop(['Geography','Gender'],axis=1,inplace=True)

#Concat the factor varaibles to the idependent variables
IndependentVar=pd.concat([X,geography,gender],axis=1)

#divide the input features into trainings and test set's
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(IndependentVar,Y,test_size=0.2,random_state=0)

#use standardscalar to standardize the featureset to one level.
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
def build_classifier(optimizer):
    classifier= Sequential()
    classifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11))
    classifier.add(Dropout(p=0.1))
    classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))
    classifier.add(Dropout(p=0.1))
    classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))
    classifier.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])
    return classifier
classifier=KerasClassifier(build_fn=build_classifier)
#Tuning of parameters using K-Fold Crossvalidation
parameters={'batch_size':[25,32],'nb_epoch':[100,500],'optimizer':['adam','rmsprop']}
grid_Search=GridSearchCV(estimator=classifier,param_grid=parameters,scoring='accuracy',cv=10) #use gridsearch to find the best parameters from speceied list.
grid_search=grid_Search.fit(X_train,Y_train)
best_param=grid_search.best_params_
best_accu=grid_search.best_score_
