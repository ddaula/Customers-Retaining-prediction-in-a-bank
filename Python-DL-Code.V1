#Basic Neural Network for predicting whether a customer will stay with the bank or leave the bank based on the feature set provided.

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#Read the file
dataset=pd.read_csv('C:/Users/Darmesh_D/Documents/deep learning/Artificial_Neural_Networks/Artificial_Neural_Networks/Churn_Modelling.csv')

X=dataset.copy()
Y=dataset.copy()
#Drop the features which donot contribute to the training/predictions.
#X contains independent variables/features
X.drop(['RowNumber', 'CustomerId', 'Surname','Exited'],axis=1,inplace=True)
#Y contains the actual(Output) values.
Y.drop(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',
       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',
       'IsActiveMember', 'EstimatedSalary'],axis=1,inplace=True)

#create factor variable for string type features
geography=pd.get_dummies(X['Geography'],drop_first=True)
gender=pd.get_dummies(X['Gender'],drop_first=True)

#drop the columns after the factore variables are created.
X.drop(['Geography','Gender'],axis=1,inplace=True)

#Concat the factor varaibles to the idependent variables
IndependentVar=pd.concat([X,geography,gender],axis=1)

#divide the input features into trainings and test set's
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(IndependentVar,Y,test_size=0.2,random_state=0)

#use standardscalar to standardize the featureset to one level.
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.fit_transform(X_test)

#Build a two layer ANN using keras package. The Sequential model is a linear stack of layers. using the Add method to add layers.
import keras
from keras.models import Sequential
from keras.layers import Dense
classifier= Sequential()
classifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11)) #first layer
classifier.add(Dropout(p=0.1))
classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))              #second layer
classifier.add(Dropout(p=0.1))
classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))           #output using sigmoid funtion to get an output b/w 0 or 1
classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])  #compile the NN
classifier.fit(X_train,Y_train,batch_size=10,epochs=100) #feed the input in a batch size of 10(weights change per 10 inputs) and whole input set 100 times.

#predict the NN with the Test set and check for accuracy.
y_pred=classifier.predict(X_test)
y_pred=(y_pred > 0.5)
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(Y_test,y_pred)
